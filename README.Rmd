---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# bagofpatternsr

<!-- badges: start -->
<!-- badges: end -->

The goal of bagofpatternsr is to provide a simple implementation of the 'Bag of Patterns' time series classification algorithm as described by Lin et al (2012). It's based on the description at timeseriesclassification.com - there are other implementations of it in R, but some are built in Java which can be tricky to run.

It uses the `seewave::` implementation of Symbolic Aggregate eXPressions (SAX) for the patterns, `data.table::` for data munging and `FNN::` for fast K-Nearest Neighbours matching.

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("mattsq/bagofpatternsr")
```
## Example

Using it is easy! Models are fit like so:

```{r train_1}
library(bagofpatternsr)
data("FaceAll_TRAIN")
data("FaceAll_TEST")
model <- bagofpatternsr::bagofpatterns_knn(FaceAll_TRAIN, 
                                           target = "target",
                                           window_size = 20,
                                           verbose = FALSE,
                                           normalize = TRUE,
                                           alphabet_size = 2, 
                                           word_size = 4,
                                           k = 1)
print(model)
```

Predictions on new datasets can be retrieved like so:

```{r predict_1}
new_preds  <- predict(model, 
                newdata = FaceAll_TEST,
                verbose = FALSE)
table(new_preds, FaceAll_TEST$target)
mean(new_preds == FaceAll_TEST$target)

```

There's support for the entirely atheoretical idea of 'sparse windows' - essentially, rather than generating a dictionary out of every single window, we take inspiration from Time Series Forest by taking `sqrt(m)` random windows from each vector. It speed up training dramatically, and seems to improve generalization - compare:

```{r train_2_nosparse}
library(tsforest)
data("FreezerRegularTrain_TRAIN")

model <- bagofpatterns_knn(FreezerRegularTrain_TRAIN, 
                           window_size = 20, 
                           sparse_windows = FALSE,
                           normalize = TRUE,
                           verbose = FALSE, 
                           alphabet_size = 3,
                           word_size = 8,
                           k = 1)

preds <- predict(model, FreezerRegularTrain_TEST, verbose = FALSE)

table(preds, FreezerRegularTrain_TEST$target)
mean(preds == FreezerRegularTrain_TEST$target)
```

With:

```{r train_2_sparse}
data("FreezerRegularTrain_TRAIN")

model <- bagofpatterns_knn(FreezerRegularTrain_TRAIN, 
                           window_size = 20, 
                           sparse_windows = TRUE, 
                           verbose = FALSE, 
                           alphabet_size = 3,
                           word_size = 8,
                           k = 1)

preds <- predict(model, FreezerRegularTrain_TEST, verbose = FALSE)

table(preds, FreezerRegularTrain_TEST$target)
mean(preds == FreezerRegularTrain_TEST$target)
```

You can also use `fit_bagofpatterns` and `bake_bagofpatterns` to use the underlying Bag Of Patterns representation for other models. Here's a simple example using logistic regression instead of K-Nearest Neighbors:

```{r}
data("FreezerRegularTrain_TRAIN")
data("FreezerRegularTrain_TEST")

bop_obj <- fit_bagofpatterns(FreezerRegularTrain_TRAIN,
                              window_size = 20, 
                              sparse_windows = FALSE, 
                              verbose = FALSE, 
                              alphabet_size = 3,
                              word_size = 8)

FreezerRegularTrain_TRAIN_conv <- bake_bagofpatterns(bop_obj)

glm_model <- glm(target ~ ., data = FreezerRegularTrain_TRAIN_conv, family = "binomial")
summary(glm_model)
```

We can generate predictions by calling `bake_bagofpatterns` on a new dataset:

```{r}
FreezerRegularTrain_TEST_conv  <- bake_bagofpatterns(bop_obj, FreezerRegularTrain_TEST)

preds <- predict(glm_model, FreezerRegularTrain_TEST_conv, type = "response")

preds <- as.numeric(preds>=0.5) + 1

table(preds, FreezerRegularTrain_TEST$target)


```
